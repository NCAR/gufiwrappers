#!/usr/bin/env python

import os
import sys
import argparse
import numpy as np
import builddb as bdb
import gmapfuncs as gmap
import dsplyfunc as dpy
from multiprocessing import Pool
from datetime import datetime
import time

errorfile = 'error_' + str(os.getpid()) + '.out'
sys.stderr = open(errorfile, 'w')
print("The command line was: ",file=sys.stderr)
print(sys.argv,file=sys.stderr)

bdb.MAXHBINS = 1024  # Maximum histogram bins

def setFilterByUids( uids ):
    """
    sets the filter DB
    """
    for uid in uids:
       bdb.fuidpid.append( gmap.getUid( uid )) 

def setFilterByPids( pids ):
    """
    sets the filter DB
    """
    for pid in pids:
       bdb.fuidpid.append( gmap.getPid( pid )) 

defcachepref = os.path.join('/gpfs/fs1/scratch', os.environ['LOGNAME'], 'gufi_cache')

parser = argparse.ArgumentParser(description='Cache tree DB for finegrain queries')

grprprtby = parser.add_mutually_exclusive_group(required=False)
grprprtby.add_argument('--by-users', dest='byusers', action='store_true',
                       help='report by user-name / user-ids (if mapping not found)')
grprprtby.add_argument('--by-projects', dest='byprojects', action='store_true', 
                       help='report by project-name / project-id (if mapping not found) HPSS only')
grprprtby.add_argument('--by-subdirs-of=', dest='subdirsof',  metavar='[Parent directory]',
                       help='report by subdirectories of this parent directory')

parser.add_argument('--filter-by-unames=', dest='fuids', nargs='+', metavar='[User1,User2,..]',
                    help='Report only for User1[,User2]..')
parser.add_argument('--filter-by-projects=', dest='fpids', nargs='+', metavar='[Project1,Project2,..]',
                    help='Report only for Project1[,Project2]..')

parser.add_argument('-n', '--ncores', dest='ncores', default=1, metavar='number-of-cores or processes',
                      help='Number of cores / threads to run')
parser.add_argument('--nsbins', dest='nsbins', default=8, metavar='number-of-histogram bins [8]',
                       help='Number of write / read stat histogram bins')
parser.add_argument('--hist', dest='hist', nargs='+', metavar='Histogram output file',
                       help='CSV file name for histgram data')
parser.add_argument(dest='cache_files', nargs='+',  help='All cache files generated by gext_cache')
args = parser.parse_args()

cfiles = args.cache_files
ncores = int(args.ncores)
nsbins = int(args.nsbins)

if not args.fuids == None:
    setFilterByUids( args.fuids[0].split(',') )

if not args.fpids == None:
    setFilterByPids( args.fpids[0].split(',') )

if args.byprojects:
   bdb.prefixdir = '/'
   activefunc = bdb.dataByProjs
   header = "Projs"
elif args.subdirsof:
   bdb.prefixdir = gmap.fsnameToSearch( args.subdirsof )
   activefunc = bdb.dataBySubDirs
   header = "Subdirs"
else:
   bdb.prefixdir = '/'
   activefunc = bdb.dataByUids
   header = "Uname/Uids"

res, total, basedir = bdb.getDataByFields(ncores, activefunc, cfiles )
dpy.displayDataByKey( res, total, basedir, nsbins, header )

if not args.hist == None:
   dpy.dumpHistByKey( res, header, args.hist[0] )

sys.stderr.close()
